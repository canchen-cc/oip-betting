{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9da0ff5e-5fc6-4b8f-9506-b56a06266cd5",
   "metadata": {},
   "source": [
    "# One Example for detecting LLM-generated Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7974df-c28e-4e70-955c-cee96acccada",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Both H0 & H1 scenarios are considered.\n",
    "**H0**: one sequence is scores of texts sampled from XSum Dataset, the other one is scores for real Olympic News.\n",
    "**H1**: one sequence is scores of texts sampled from XSum Dataset, the other one is scores for fake news generated by Gemini-1.5-Pro.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2329c83f-da7a-426d-8cbd-186bfa20eb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# With OAlg method being Online Newton Step (ONS)\n",
    "echo \"$(date), Setting up environment ...\"\n",
    "mkdir -p results \n",
    "python scripts/bet_ons.py --file1 \"Detect_LLM/data/xsum.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type1 \"real\" \\\n",
    "                             --file2 \"Detect_LLM/data/olympic.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type2 \"samples\" \\\n",
    "                             --file3 \"Detect_LLM/data/olympic.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type3 \"real\" \\\n",
    "                             --iters 300 --shift_time None --output_file \"Detect_LLM/results/pro.neo2.7.fast.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f155774a-d445-4f4d-850a-24221c203fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# With OAlg method being FTRL+Barrier\n",
    "echo \"$(date), Setting up environment ...\"\n",
    "mkdir -p results \n",
    "python scripts/bet_ftrl_barrier.py --file1 \"Detect_LLM/data/xsum.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type1 \"real\" \\\n",
    "                             --file2 \"Detect_LLM/data/olympic.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type2 \"samples\" \\\n",
    "                             --file3 \"Detect_LLM/data/olympic.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type3 \"real\" \\\n",
    "                             --iters 300 --shift_time None --output_file \"Detect_LLM/results/pro.neo2.7.fast.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ded7d73-cf51-4b5c-a53a-95a3af2634f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# With OAlg method being Optimistic-FTRL+Barrier\n",
    "echo \"$(date), Setting up environment ...\"\n",
    "mkdir -p results \n",
    "python scripts/bet_optimistic_ftrl_barrier.py --file1 \"Detect_LLM/data/xsum.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type1 \"real\" \\\n",
    "                             --file2 \"Detect_LLM/data/olympic.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type2 \"samples\" \\\n",
    "                             --file3 \"Detect_LLM/data/olympic.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json\" --type3 \"real\" \\\n",
    "                             --iters 300 --shift_time None --output_file \"Detect_LLM/results/pro.neo2.7.fast.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565fbdcd-8486-4877-a03c-348a08a4f253",
   "metadata": {},
   "source": [
    "# Get Results to Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c66c2-616a-446b-a2aa-8917265f75b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18dd4e3-66f6-4e13-bad5-0bb039e3abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "json_files = ['Detect_LLM/results/pro.neo2.7.fast.json']\n",
    "item_names = ['ONS','FTRL+Barrier', 'Optimistic-FTRL+Barrier']\n",
    "data_collect = {name: {'rejection_time': [], 'power': [], 'fpr': []} for name in item_names}\n",
    "\n",
    "\n",
    "for file in json_files:\n",
    "    with open(file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for i, item in enumerate(data):  \n",
    "            data_collect[item_names[i]]['rejection_time'].append(item['rejection_time'])\n",
    "            data_collect[item_names[i]]['power'].append(item['power'])\n",
    "            data_collect[item_names[i]]['fpr'].append(item['fpr'])\n",
    "\n",
    "\n",
    "results = []\n",
    "for name, metrics in data_collect.items():\n",
    "    avg_rejection_time = np.mean(metrics['rejection_time'], axis=0).tolist()\n",
    "    avg_power = np.mean(metrics['power'], axis=0).tolist()\n",
    "    avg_fpr = np.mean(metrics['fpr'], axis=0).tolist()\n",
    "    results.append({\n",
    "        'item_name': name,\n",
    "        'rejection_time': avg_rejection_time,\n",
    "        'power': avg_power,\n",
    "        'fpr': avg_fpr\n",
    "    })\n",
    "\n",
    "results_json = json.dumps(results, indent=4)\n",
    "\n",
    "with open('Detect_LLM/results_to_plot/pro.neo2.7.fast.json', 'w') as f:\n",
    "    f.write(results_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd4896a-4772-4706-8e85-52b4e9d8bde4",
   "metadata": {},
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d44ed8-2123-4428-bb39-b2b892174756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('Detect_LLM/results_to_plot/flash.neo2.7.eta1_300.json', 'r') as file:\n",
    "    items = json.load(file)\n",
    "\n",
    "df_list = []\n",
    "for item in items:\n",
    "    df = pd.DataFrame({\n",
    "        'rejection_time': item['rejection_time'],\n",
    "        'fpr': item['fpr'],\n",
    "        'name': item['item_name'],  \n",
    "        'alpha': np.linspace(0.005, 0.1, len(item['fpr']))  \n",
    "    })\n",
    "    df_list.append(df)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(13, 4.2)) \n",
    "i=0\n",
    "markers = [\"*\", \"s\", \"^\"]\n",
    "for df in df_list:\n",
    "    ax[0].plot(df['rejection_time'], df['fpr'],ls='--', lw=3,  marker=markers[i], label=df['name'].iloc[0], markersize=9)\n",
    "    ax[1].plot(df['alpha'], df['fpr'], ls='--', lw=3, marker=markers[i], label=df['name'].iloc[0], markersize=9)\n",
    "    i += 1\n",
    "\n",
    "ax[0].tick_params(axis='both', labelsize=20, which='major', length=10,  width=2)\n",
    "ax[0].set_ylim(-0.005,0.105)\n",
    "ax[0].set_yticks(np.arange(0,0.105,0.02))\n",
    "ax[0].set_xlim(-10,160)\n",
    "ax[0].set_xticks(np.arange(0,160, 30))\n",
    "ax[0].set_xlabel(r'Rejection Time ($\\tau$)', fontsize=20)\n",
    "ax[0].set_ylabel('False Positive Rate (FPR)', fontsize=20)\n",
    "\n",
    "x = np.linspace(0, 0.1, 500)\n",
    "y = x \n",
    "ax[1].fill_between(x, 0, y, color='yellow', alpha=0.1, zorder=1)  \n",
    "\n",
    "ax[1].set_ylim(-0.005,0.105)\n",
    "ax[1].set_yticks(np.arange(0,0.105,0.02))\n",
    "\n",
    "ax[1].set_xlim(-0.005,0.105)\n",
    "ax[1].set_xticks(np.arange(0,0.12,0.02))\n",
    "ax[1].tick_params(axis='both', labelsize=20, which='major', length=10,  width=2)\n",
    "ax[1].plot([0, 0.1], [0, 0.1], color='k', ls='--',  lw=3)\n",
    "ax[1].set_xlabel(r'Significance Level ($\\alpha$)', fontsize=20)\n",
    "ax[1].set_ylabel('False Positive Rate (FPR)', fontsize=20)\n",
    "\n",
    "\n",
    "handles, labels = next(ax.flat).get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.49, -0.07), fancybox=True, shadow=True,\n",
    "             ncol=5, fontsize=20, labelspacing=0.1, handletextpad=0.5, handlelength=1)\n",
    "plt.subplots_adjust(wspace=0.4)  \n",
    "for axis in ax:  \n",
    "    for spine in axis.spines.values():\n",
    "        spine.set_linewidth(2)  \n",
    "\n",
    "plt.savefig('Detect_LLM/plot_png/flash.neo2.7.eta1_300.png', dpi=300, bbox_inches='tight')  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894de21f-faa1-4e98-a681-b9981e08a0f3",
   "metadata": {},
   "source": [
    "# Plot Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fc2b0-49ba-464c-8bff-dc5b43d62607",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "file_paths1 = [\n",
    "    'Detect_LLM/data/xsum.gemini_1.5_flash.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json',\n",
    "    'Detect_LLM/data/xsum.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json',\n",
    "    'Detect_LLM/data/xsum.palm2.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json'\n",
    "]\n",
    "file_paths2 = [\n",
    "    'Detect_LLM/data/olympic.gemini_1.5_flash.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json',\n",
    "    'Detect_LLM/data/olympic.gemini_1.5_pro.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json',\n",
    "    'Detect_LLM/data/olympic.palm2.gpt-j-6B.gpt-neo-2.7B.sampling_discrepancy.json'\n",
    "]\n",
    "\n",
    "def load_data(file_paths, key):\n",
    "    data_accumulate = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            data_accumulate.extend(data['predictions'][key])\n",
    "    return np.array(data_accumulate)\n",
    "\n",
    "\n",
    "y1_list = [load_data([file], 'real') for file in file_paths1]\n",
    "y2_list = [load_data([file], 'samples') for file in file_paths2]\n",
    "y1_avg = np.concatenate(y1_list)\n",
    "y2_avg = np.concatenate(y2_list)\n",
    "\n",
    "label_lst=['Gemini-1.5-Flash','Gemini-1.5-Pro', 'PaLM 2']\n",
    "fig, axes = plt.subplots(2, 2, figsize=(8, 6))\n",
    "axes = axes.flatten()\n",
    "x_label = \"Value\"\n",
    "y_label = \"Frequency\"\n",
    "\n",
    "# Plot individual comparisons\n",
    "for i in range(3):\n",
    "    sns.histplot(y1_list[i], bins=30, color='dodgerblue', alpha=0.5, label='Human', kde=False, edgecolor='none', ax=axes[i])\n",
    "    sns.histplot(y2_list[i], bins=30, color='orange', alpha=0.5, label=label_lst[i], kde=False, edgecolor='none', ax=axes[i])\n",
    "    axes[i].legend(loc=\"upper left\",fontsize=11,framealpha=0.5)\n",
    "    axes[i].set_xlim(-3, 7)\n",
    "    axes[i].set_xticks(np.arange(-3, 8, 2))\n",
    "    axes[i].set_ylim(0, 80)\n",
    "    axes[i].set_yticks(np.arange(0, 81, 20))\n",
    "    axes[i].tick_params(axis='both', which='major', length=10, width=1.2, labelsize=10)\n",
    "\n",
    "    axes[i].set_xlabel(x_label, fontsize=15)  \n",
    "    axes[i].set_ylabel(y_label, fontsize=15)  \n",
    "\n",
    "# Plot the average comparison in the fourth subplot\n",
    "sns.histplot(y1_avg, bins=30, color='dodgerblue', alpha=0.5, label='Human', kde=False, edgecolor='none', ax=axes[3])\n",
    "sns.histplot(y2_avg, bins=30, color='orange', alpha=0.5, label='LLMs', kde=False, edgecolor='none', ax=axes[3])\n",
    "axes[3].legend(loc=\"upper left\", fontsize=11,framealpha=0.5)\n",
    "axes[3].set_xlim(-3, 7)\n",
    "axes[3].set_xticks(np.arange(-3, 8, 2))\n",
    "axes[3].set_ylim(0, 200)\n",
    "axes[3].tick_params(axis='both', which='major', length=10, width=1.2, labelsize=10)\n",
    "axes[3].set_xlabel(x_label, fontsize=15)  \n",
    "axes[3].set_ylabel(y_label, fontsize=15)  \n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.tick_params(axis='both', which='major', length=10, width=1.5, labelsize=15)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_linewidth(1.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('Detect_LLM/plot_png/all_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
